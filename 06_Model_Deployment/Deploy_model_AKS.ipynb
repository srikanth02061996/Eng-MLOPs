{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy model as a webservice on Azure Kubernetes Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Prerequisites](#prerequisites)\n",
    "\n",
    "2. [Initialize workspace](#workspace)\n",
    "\n",
    "3. [Deploy Model to AKS](#deploymodel)\n",
    "\n",
    "- a) [Create scoring file](#scoringfile)\n",
    "- b) [Define Enviroment](#env)\n",
    "- c) [Deployment configuration](#configfile)\n",
    "- d  [Deploy Webservice](#webservice)\n",
    "- e) [Test Webservice](#testservice)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prerequisites <a id='prerequisites'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import azureml.core\n",
    "\n",
    "# display the core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize workspace <a id='workspace'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLOps_WS\n",
      "Learn_MLOps\n",
      "northeurope\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Deploy model <a id='deploymodel'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Create a scoring script <a id='scoringfile'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import onnxruntime\n",
    "import time\n",
    "from azureml.core.model import Model\n",
    "from azureml.monitoring import ModelDataCollector\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "\n",
    "def init():\n",
    "    global model, scaler, input_name, label_name, inputs_dc, prediction_dc\n",
    "    \n",
    "\n",
    "    scaler_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'scaler/1/scaler.pkl')\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    \n",
    "    model_onnx = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'support-vector-classifier/2/svc.onnx')\n",
    "    # print(os.listdir(model_onnx))\n",
    "    model = onnxruntime.InferenceSession(model_onnx, None)\n",
    "    input_name = model.get_inputs()[0].name\n",
    "    label_name = model.get_outputs()[0].name\n",
    "    \n",
    "    # variables to monitor model input and output data\n",
    "    inputs_dc = ModelDataCollector(\"Support vector classifier model\", designation=\"inputs\", feature_names=[\"feat1\", \"feat2\", \"feat3\", \"feat4\", \"feat5\", \"feat6\", \"feat7\"])\n",
    "    prediction_dc = ModelDataCollector(\"Support vector classifier model\", designation=\"predictions\", feature_names=[\"weatherprediction\"])\n",
    "\n",
    "    \n",
    "@input_schema('data', NumpyParameterType(np.array([[34.927778, 0.24, 7.3899, 83, 16.1000, 1016.51, 1]])))\n",
    "@output_schema(NumpyParameterType(np.array([0])))\n",
    "def run(data):\n",
    "                try: \n",
    "                    data = scaler.fit_transform(data.reshape(1, 7))\n",
    "                    inputs_dc.collect(data)\n",
    "                    \n",
    "                    # model inference\n",
    "                    result = model.run([label_name], {input_name: data.astype(np.float32)})[0]\n",
    "                    # this call is saving model output data into Azure Blob\n",
    "                    prediction_dc.collect(result)\n",
    "\n",
    "                 \n",
    "                except Exception as e:   \n",
    "                    result = 'error'\n",
    "                    prediction_dc.collect(result)\n",
    "                    \n",
    "                return result.tolist()            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Define Environment <a id='env'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "Environment(name=\"myenv\")\n",
    "\n",
    "#env = Environment.get(workspace=ws, name=\"AzureML-Minimal\")\n",
    "env = Environment.get(workspace=ws, name=\"AzureML-Minimal\").clone('myenv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pip_package in [\"numpy\", \"onnxruntime\", \"joblib\", \"azureml-core\", \"azureml-monitoring\", \"azureml-defaults\", \"scikit-learn==0.22.2.post1\",\"azure-ml-api-sdk\", \"inference-schema\", \"inference-schema[numpy-support]\"]:\n",
    "    env.python.conda_dependencies.add_pip_package(pip_package)\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='score.py',\n",
    "                                    environment=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Deployment Configuration <a id='configfile'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice\n",
    "\n",
    "aks_config = AksWebservice.deploy_configuration(collect_model_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Deploy web service <a id='webservice'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating...................................................................................................................................................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "\n",
    "# Choose a name for your AKS cluster\n",
    "aks_name = 'port-aks' \n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    aks_target = ComputeTarget(workspace=ws, name=aks_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # Use the default configuration (can also provide parameters to customize)\n",
    "    prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "    # Create the cluster\n",
    "    aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                    name = aks_name, \n",
    "                                    provisioning_configuration = prov_config)\n",
    "\n",
    "if aks_target.get_status() != \"Succeeded\":\n",
    "    aks_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(ws, 'scaler')\n",
    "model2 = Model(ws, 'support-vector-classifier')\n",
    "\n",
    "service_name = 'weather-aks-prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running.........................\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(ws, service_name, models=[model1, model2], inference_config=inference_config, deployment_config=aks_config, deployment_target=aks_target,overwrite=True)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-14T10:58:43,546482549+00:00 - rsyslog/run \n",
      "2020-12-14T10:58:43,546763446+00:00 - gunicorn/run \n",
      "2020-12-14T10:58:43,546709547+00:00 - iot-server/run \n",
      "2020-12-14T10:58:43,553550295+00:00 - nginx/run \n",
      "/bin/bash: /azureml-envs/azureml_dc5f278073e04eb55ee471b41f906276/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_dc5f278073e04eb55ee471b41f906276/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_dc5f278073e04eb55ee471b41f906276/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_dc5f278073e04eb55ee471b41f906276/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "bash: /azureml-envs/azureml_dc5f278073e04eb55ee471b41f906276/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_dc5f278073e04eb55ee471b41f906276/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_dc5f278073e04eb55ee471b41f906276/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_dc5f278073e04eb55ee471b41f906276/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_dc5f278073e04eb55ee471b41f906276/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_dc5f278073e04eb55ee471b41f906276/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "/bin/bash: /azureml-envs/azureml_dc5f278073e04eb55ee471b41f906276/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2020-12-14T10:58:43,632809897+00:00 - iot-server/finish 1 0\n",
      "2020-12-14T10:58:43,634220386+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (11)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2020-12-14 10:58:45,321 | root | INFO | Starting up app insights client\n",
      "Starting up app insights client\n",
      "2020-12-14 10:58:45,321 | root | INFO | Starting up request id generator\n",
      "Starting up request id generator\n",
      "2020-12-14 10:58:45,321 | root | INFO | Starting up app insight hooks\n",
      "Starting up app insight hooks\n",
      "2020-12-14 10:58:45,321 | root | INFO | Invoking user's init function\n",
      "Invoking user's init function\n",
      "2020-12-14 10:58:45,706 - azureml.monitoring._logging.telemetry_logger.modeldatacollector - INFO - ActivityStarted, mdc_init - activity_id:078115f7-4ce5-4f18-a3f6-9977fdd9080b activity_name:mdc_init activity_type:InternalCall sdk_version:1.19.0 telemetry_component_name:azureml.monitoring arm_id:6faa9ede-4786-48dc-9c1e-0262e2844ebf/learn_mlops/mlops_ws location:northeurope hostname:weather-aks-prediction-547f8764cb-gr52b sampling_rate:0.01\n",
      "2020-12-14 10:58:45,710 - azureml.monitoring._logging.telemetry_logger.modeldatacollector - INFO - MDC is initialized - activity_id:078115f7-4ce5-4f18-a3f6-9977fdd9080b activity_name:mdc_init activity_type:InternalCall sdk_version:1.19.0 telemetry_component_name:azureml.monitoring arm_id:6faa9ede-4786-48dc-9c1e-0262e2844ebf/learn_mlops/mlops_ws location:northeurope hostname:weather-aks-prediction-547f8764cb-gr52b sampling_rate:0.01\n",
      "2020-12-14 10:58:45,710 - azureml.monitoring._logging.telemetry_logger.modeldatacollector - INFO - ActivityCompleted: Activity=mdc_init, HowEnded=Success, Duration=3.63 [ms] - activity_id:078115f7-4ce5-4f18-a3f6-9977fdd9080b activity_name:mdc_init activity_type:InternalCall completionStatus:Success durationMs:3.63 sdk_version:1.19.0 telemetry_component_name:azureml.monitoring arm_id:6faa9ede-4786-48dc-9c1e-0262e2844ebf/learn_mlops/mlops_ws location:northeurope hostname:weather-aks-prediction-547f8764cb-gr52b sampling_rate:0.01\n",
      "2020-12-14 10:58:45,722 - azureml.monitoring._logging.telemetry_logger.modeldatacollector - INFO - ActivityStarted, mdc_init - activity_id:a3838d3b-b258-4673-848a-e5e54d1fa7de activity_name:mdc_init activity_type:InternalCall sdk_version:1.19.0 telemetry_component_name:azureml.monitoring arm_id:6faa9ede-4786-48dc-9c1e-0262e2844ebf/learn_mlops/mlops_ws location:northeurope hostname:weather-aks-prediction-547f8764cb-gr52b sampling_rate:0.01\n",
      "2020-12-14 10:58:45,722 - azureml.monitoring._logging.telemetry_logger.modeldatacollector - INFO - MDC is initialized - activity_id:a3838d3b-b258-4673-848a-e5e54d1fa7de activity_name:mdc_init activity_type:InternalCall sdk_version:1.19.0 telemetry_component_name:azureml.monitoring arm_id:6faa9ede-4786-48dc-9c1e-0262e2844ebf/learn_mlops/mlops_ws location:northeurope hostname:weather-aks-prediction-547f8764cb-gr52b sampling_rate:0.01\n",
      "2020-12-14 10:58:45,722 - azureml.monitoring._logging.telemetry_logger.modeldatacollector - INFO - ActivityCompleted: Activity=mdc_init, HowEnded=Success, Duration=0.53 [ms] - activity_id:a3838d3b-b258-4673-848a-e5e54d1fa7de activity_name:mdc_init activity_type:InternalCall completionStatus:Success durationMs:0.53 sdk_version:1.19.0 telemetry_component_name:azureml.monitoring arm_id:6faa9ede-4786-48dc-9c1e-0262e2844ebf/learn_mlops/mlops_ws location:northeurope hostname:weather-aks-prediction-547f8764cb-gr52b sampling_rate:0.01\n",
      "2020-12-14 10:58:45,722 | root | INFO | Users's init has completed successfully\n",
      "Users's init has completed successfully\n",
      "2020-12-14 10:58:45,725 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2020-12-14 10:58:45,725 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2020-12-14 10:58:45,726 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "2020-12-14 10:58:55,007 | root | INFO | 200\n",
      "200\n",
      "127.0.0.1 - - [14/Dec/2020:10:58:55 +0000] \"GET /swagger.json HTTP/1.0\" 200 2137 \"-\" \"-\"\n",
      "2020-12-14 10:59:00,151 | root | INFO | 200\n",
      "200\n",
      "127.0.0.1 - - [14/Dec/2020:10:59:00 +0000] \"GET /swagger.json HTTP/1.0\" 200 2137 \"-\" \"-\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.update(enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Test web service <a id='testservice'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://52.138.181.244:80/api/v1/service/weather-aks-prediction/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://52.138.181.244:80/api/v1/service/weather-aks-prediction/swagger.json\n"
     ]
    }
   ],
   "source": [
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Healthy'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "input_payload = json.dumps({\n",
    "    'data': [[34.927778, 0.24, 7.3899, 83, 16.1000, 1016.51, 1]],\n",
    "    'method': 'predict'  # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
    "})\n",
    "\n",
    "output = service.run(input_payload)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
